{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3c342a-93dd-471a-bb32-91c165ca3b6a",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## üß© 1. Feature Creation\r\n",
    "\r\n",
    "**üéØ Goal:** Create new features from existing data to improve model performance.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### üîπ Techniques\r\n",
    "\r\n",
    "- **Math-based Combinations:**  \r\n",
    "  `price_per_unit = total_price / quantity`\r\n",
    "\r\n",
    "- **Date/Time Features:**  \r\n",
    "  Extract components like `day`, `month`, `year`, `weekday`, `is_weekend`, `hour`, etc.\r\n",
    "\r\n",
    "- **Group Aggregations:**  \r\n",
    "  Calculate metrics such as:\r\n",
    "  - Mean purchase per user  \r\n",
    "  - Count of items bought  \r\n",
    "  - Total value by category\r\n",
    "\r\n",
    "- **Domain-Specific Logic:**  \r\n",
    "  Example:  \r\n",
    "  `BMI = weight / height¬≤` *(useful in healthcare or fitness datasets)*\r\n",
    "\r\n",
    "- **Text-Based Stats:**  \r\n",
    "  - Word count  \r\n",
    "  - Sentence length  \r\n",
    "  - Presence of specific keywords  \r\n",
    "  - Special character frequency\r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5242e8-f795-4e22-8b92-1704ed93ebb5",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r",
    "## üîÅ 2. Feature Transformation\r\n",
    "\r\n",
    "**üéØ Goal:** Modify the distribution or scale of features to make them suitable for machine learning algorithms.\r\n",
    "### üîπ Techniques\n",
    "\n",
    "- `Data Encoding`\n",
    "   - Nominal / One hot encoding\n",
    "   - Label and ordinal encoding\n",
    "   - Target guided ordinal encoding\n",
    "| Encoding Method                     | Description                              | Best For                                           |\r\n",
    "| ----------------------------------- | ---------------------------------------- | -------------------------------------------------- |\r\n",
    "| **Label Encoding**                  | Assigns integer values to each category  | Ordinal categories (e.g., \"low\", \"medium\", \"high\") |\r\n",
    "| **One-Hot Encoding**                | Creates binary columns for each category | Nominal categories, small cardinality              |\r\n",
    "| **Binary Encoding**                 | Converts categories to binary code       | High-cardinality nominal features                  |\r\n",
    "| **Frequency / Count Encoding**      | Replaces category with frequency/count   | When category frequency matters                    |\r\n",
    "| **Target Encoding (Mean Encoding)** | Uses average of target for each category | Risk of leakage, use with caution                  |\r\n",
    "| **Ordinal Encoding**                | Manually assigns ordered labels          | Ordered categories                                 |\r\n",
    "\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### ‚öôÔ∏è Function Transformers\r\n",
    "- `Log Transform`  \r\n",
    "- `Square Transform`  \r\n",
    "- `Square Root Transform`  \r\n",
    "- `Reciprocal Transform`  \r\n",
    "- `Custom Transform` (user-defined)\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### üìà Power Transformation Techniques\r\n",
    "1. **Box-Cox Transform** *(requires positive values)*\r\n",
    "2. **Yeo-Johnson Transform** *(handles zero and negative values)*\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### üìä Quantile Transformers\r\n",
    "Quantile transformation techniques are used to map numerical features to a uniform or normal distribution.  \r\n",
    "They are useful when dealing with skewed data and can be implemented using `sklearn.preprocessing.QuantileTransformer`.\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.preprocessing import QuantileTransformer\r\n",
    "\r\n",
    "qt = QuantileTransformer(output_distribution='normal')  # or 'uniform'\r\n",
    "X_transformed = qt.fit_transform(X)\r\n",
    ".ormform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122915d-4301-4be3-900a-7a88bd5809aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Feature Extraction\n",
    "Goal: Automatically convert raw or unstructured data into feature vectors.\n",
    "\n",
    "---\n",
    "### üîπ Techniquesal.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 1Ô∏è‚É£ Statistical Methods\r\n",
    "\r\n",
    "Used to summarize patterns and relationships in numeric data.\r\n",
    "\r\n",
    "- **Mean** ‚Äì Average value of the dataset  \r\n",
    "- **Median** ‚Äì Middle value in a sorted list  \r\n",
    "- **Standard Deviation** ‚Äì Measure of spread in the data  \r\n",
    "- **Correlation & Covariance** ‚Äì Measure of relationships between variables  \r\n",
    "- **Regression Analysis** ‚Äì Model the relationship between dependent and independent variables\r\n",
    "\r\n",
    "> ‚úÖ These methods capture trends, variability, and relationships in the data.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 2Ô∏è‚É£ Dimensionality Reduction Techniques\r\n",
    "\r\n",
    "Dimensionality reduction simplifies high-dimensional data while preserving meaningful structure.\r\n",
    "\r\n",
    "### üîπ Principal Component Analysis (PCA)\r\n",
    "- Unsupervised technique\r\n",
    "- Projects data into a lower-dimensional space\r\n",
    "- Preserves the maximum variance\r\n",
    "\r\n",
    "### üîπ Linear Discriminant Analysis (LDA)\r\n",
    "- Supervised technique\r\n",
    "- Maximizes class separability\r\n",
    "- Best for classification problems\r\n",
    "\r\n",
    "### üîπ Autoencoders\r\n",
    "- Neural network-based compression technique\r\n",
    "- Learns a lower-dimensional latent representation\r\n",
    "- Useful for anomaly detection, denoising, and data generation\r\n",
    "\r\n",
    "### üîπ t-SNE (t-Distributed Stochastic Neighbor Embedding)\r\n",
    "- Non-linear dimensionality reduction\r\n",
    "- Maintains local structure\r\n",
    "- Best for data visualization\r\n",
    "\r\n",
    "### üîπ Independent Component Analysis (ICA)\r\n",
    "- Separates signals into statistically independent components\r\n",
    "- Useful in blind source separation (e.g., separating audio signals)\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 3Ô∏è‚É£ Textual Data Feature Extraction\r\n",
    "\r\n",
    "Used in **Natural Language Processing (NLP)** to transform text into numerical form.\r\n",
    "\r\n",
    "### üî∏ Bag of Words (BoW)\r\n",
    "- Represents text as word frequency vectors\r\n",
    "- Ignores grammar and word order\r\n",
    "\r\n",
    "### üî∏ Term Frequency‚ÄìInverse Document Frequency (TF-IDF)\r\n",
    "- Weighs word frequency relative to document rarity\r\n",
    "- Highlights important but rare terms\r\n",
    "\r\n",
    "> üí° Both are used for text classification, document clustering, and search engines.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 4Ô∏è‚É£ Signal Processing Techniques\r\n",
    "\r\n",
    "Used for audio, time series, and waveform data.\r\n",
    "\r\n",
    "### üîπ Fourier Transform\r\n",
    "- Converts signals from time domain to frequency domain\r\n",
    "- Identifies frequency components\r\n",
    "\r\n",
    "### üîπ Wavelet Transform\r\n",
    "- Captures both time and frequency information\r\n",
    "- Ideal for non-stationary signals (e.g., ECG, stock prices)\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 5Ô∏è‚É£ Image Data Feature Extraction\r\n",
    "\r\n",
    "Used in computer vision and image recognition.\r\n",
    "\r\n",
    "### üî∏ Histogram of Oriented Gradients (HOG)\r\n",
    "- Computes edge directions and intensities\r\n",
    "- Common in object detection (e.g., pedestrian detection)\r\n",
    "\r\n",
    "### üî∏ Scale-Invariant Feature Transform (SIFT)\r\n",
    "- Extracts robust, rotation- and scale-invariant features\r\n",
    "- Used for object matching and image stitching\r\n",
    "\r\n",
    "### üî∏ Convolutional Neural Networks (CNN)\r\n",
    "- Learn hierarchical visual features automatically\r\n",
    "- Widely used in image classificdatasets.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "\n",
    "- `Feature Scaling`\n",
    "    - Standardization\n",
    "    - Normalization\n",
    "    - Unit Vector \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e0973-4c1c-4ca9-b99a-7c84b3cc6079",
   "metadata": {},
   "source": [
    "# 4. Feature Scaling\n",
    "\n",
    "    - Standardization\n",
    "    - Normalization\n",
    "    - Unit Vector "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b050c0e-8be8-4880-9097-67b86fd7dd50",
   "metadata": {},
   "source": [
    "# 5. Feature selection\n",
    "\n",
    "    - Filter method\n",
    "    - Embedded method\n",
    "    - Wrapper method\n",
    "\n",
    "- `PCA (Principal component analysis)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5c449-d324-4a48-a1d8-b9706b2c19c0",
   "metadata": {},
   "source": [
    "# To handle skewed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b30e6-a16c-4552-a922-43662c96548c",
   "metadata": {},
   "source": [
    "| Skew Type      | Recommended Techniques             |\n",
    "| -------------- | ---------------------------------- |\n",
    "| Right-skewed   | Log, ‚àö, Box-Cox                    |\n",
    "| Moderate skew  | Cube root, ‚àö                       |\n",
    "| Includes 0/-ve | Yeo-Johnson, Cube root             |\n",
    "| Extreme values | Winsorization, QuantileTransformer |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd49f6d-aa85-41ec-9101-1ac0f86eb2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0c6aa-6e93-4b3b-9ddb-d9ef2df8d7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e1912-814c-426b-81fb-c979f22d761e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368a7b2-c129-4573-b9cb-82e373599bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba232201-aa42-4bbb-bedf-c161ce566d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18be6ec-7b70-45c2-8bc3-c70d8764e471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65e045-6077-4924-aefe-70e762527d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345e437-ee47-4593-94ff-84925ad70b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0007ef-1827-4b7e-ba9a-58ab5b02f707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
